{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook for neural network models creation and metrics calculation.\n",
    "\n",
    "Created: 26/02/2019\n",
    "Author: Silvester Kosmel\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "import import_ipynb\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Conv2D,\n",
    "                                     Conv1D,\n",
    "                                     MaxPooling2D,\n",
    "                                     Flatten,\n",
    "                                     Dense,\n",
    "                                     Dropout,\n",
    "                                     Lambda,\n",
    "                                     Reshape,\n",
    "                                     Permute,\n",
    "                                     LSTM,\n",
    "                                     Bidirectional)\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up for GPU memory sharing\n",
    "# https://kobkrit.com/using-allow-growth-memory-option-in-tensorflow-and-keras-dc8c8081bc96\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "# tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from preprocessing.ipynb\n",
      "importing Jupyter notebook from audio_prep.ipynb\n",
      "importing Jupyter notebook from constants.ipynb\n",
      "0.032 31.25\n",
      "625 168\n",
      "importing Jupyter notebook from midi_prep.ipynb\n"
     ]
    }
   ],
   "source": [
    "import preprocessing as prep\n",
    "import constants as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model creation utils\"\"\"\n",
    "\n",
    "def conv2d_reshape(cqt_matrices, midi_matrices):\n",
    "    \"\"\"\n",
    "    Transpose both matrices (spectrogram and MIDI one-hot) to be in format [frames, frequency_bins/one-hot]\n",
    "    and reshape given wav matrices into the right input shape for Keras Conv2D network: (batch, rows, cols, channels)\n",
    "    \n",
    "    Args:\n",
    "    wav_matrices: array of CQT spectrograms (splitted into frames)\n",
    "    midi_matrices: labels for frames, represented as one-hot vectors\n",
    "    \n",
    "    Return:\n",
    "    Concatenated arrays of spectrograms and labels, which are used as input for neural network\n",
    "    \"\"\"\n",
    "    \n",
    "    cqt_reshaped = [np.array(cqt_chunk) for cqt_chunk in cqt_matrices]\n",
    "    cqt_reshaped = np.concatenate(cqt_reshaped)\n",
    "    cqt_reshaped = np.array([cqt.T for cqt in cqt_reshaped])\n",
    "    cqt_reshaped = np.array([cqt.reshape(2*c.CHUNK_PADDING, c.BINS_NUMBER, 1) for cqt in cqt_reshaped])\n",
    "    \n",
    "    midi_reshaped = [midi_chunk.T for midi_chunk in midi_matrices]\n",
    "    midi_reshaped = np.concatenate(midi_reshaped)  \n",
    "    \n",
    "    return cqt_reshaped, midi_reshaped\n",
    "\n",
    "def create_simple_conv_model(input_heigth, input_width, num_classes):\n",
    "    \"\"\"\n",
    "    Create simple convolutional model for one-frame transcription.\n",
    "    \n",
    "    Args:\n",
    "    input_height/input_width: input parameters defining model shape\n",
    "    num_classes: number of model output classes in Dense layer\n",
    "    \n",
    "    Return:\n",
    "    model: Sequential model with given layers\n",
    "    \"\"\"\n",
    "    \n",
    "    input_shape = (input_heigth, input_width, 1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='valid', input_shape=input_shape))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    adam_opt = Adam(lr=0.0001, decay=1e-5)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam_opt)\n",
    "    return model\n",
    "\n",
    "def create_conv_model(input_heigth, input_width):\n",
    "    \"\"\"\n",
    "    Create convolutional acoustic model for sequence predictions.\n",
    "    \n",
    "    Inspired by Kelz 2016 architecture:\n",
    "        https://github.com/rainerkelz/framewise_2016/blob/master/models.py\n",
    "    \n",
    "    Args:\n",
    "        input_height/input_width: input parameters defining model shape\n",
    "\n",
    "    Return:\n",
    "        tf.keras.Model: object with specific \n",
    "                        input (batch, input_height, input_width, 1) and\n",
    "                        output (batch, height, classes) shapes.\n",
    "    \"\"\" \n",
    "    \n",
    "    from tensorflow.keras.layers import Input\n",
    "    \n",
    "    inputs = Input(shape=(input_heigth, input_width, 1), name='init_input')\n",
    "    \n",
    "    model = Conv2D(filters=32,\n",
    "                   kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   padding='valid',\n",
    "                   name='conv1')(inputs)\n",
    "    model = Conv2D(filters=64,\n",
    "                   kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   padding='same', name='conv2')(model)\n",
    "    \n",
    "    model = MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='valid', name='max_pool1')(model)\n",
    "    model = Dropout(0.25, name='drop1')(model)\n",
    "    \n",
    "    model = Conv2D(filters=64,\n",
    "                   kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   padding='valid',\n",
    "                   name='conv3')(model)\n",
    "    \n",
    "    model = MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='valid', name='max_pool2')(model)\n",
    "    model = Dropout(0.25, name='drop2')(model)\n",
    "    \n",
    "    shapes = model.shape\n",
    "    model = Reshape((shapes[1], shapes[2].value * shapes[3].value))(model)\n",
    "    \n",
    "    outputs = Conv1D(filters=88,\n",
    "                     kernel_size=1,\n",
    "                     activation='sigmoid',\n",
    "                     padding='valid',\n",
    "                     name='conv4')(model)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "def create_acoustic_model(input_heigth, input_width):\n",
    "    \"\"\"   \n",
    "    Create acoustic model with combination of convolution and recurrent layers.\n",
    "    \n",
    "    Args:\n",
    "        input_height/input_width: input parameters defining model shape\n",
    "\n",
    "    Return:\n",
    "        tf.keras.Model: object with specific \n",
    "                        input (batch, input_height, input_width, 1) and\n",
    "                        output (batch, height, classes) shapes.\n",
    "    \"\"\" \n",
    "    \n",
    "    from tensorflow.keras.layers import Input\n",
    "    \n",
    "    inputs = Input(shape=(input_heigth, input_width, 1), name='init_input')\n",
    "    \n",
    "    model = Conv2D(filters=32,\n",
    "                   kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   padding='valid',\n",
    "                   name='conv1')(inputs)\n",
    "    model = Conv2D(filters=64,\n",
    "                   kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   padding='same', name='conv2')(model)\n",
    "    \n",
    "    model = MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='valid', name='max_pool1')(model)\n",
    "#     model = Dropout(0.25, name='drop1')(model)\n",
    "    \n",
    "    model = Conv2D(filters=64,\n",
    "                   kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   padding='valid',\n",
    "                   name='conv3')(model)\n",
    "    \n",
    "    model = MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='valid', name='max_pool2')(model)\n",
    "#     model = Dropout(0.25, name='drop2')(model)\n",
    "    \n",
    "    shapes = model.shape\n",
    "    model = Reshape((shapes[1], shapes[2].value * shapes[3].value))(model)\n",
    "    \n",
    "#     model = Conv1D(filters=768, kernel_size=1, activation='relu', padding='valid', name='conv4')(model)\n",
    "#     model = Dropout(0.5, name='drop3')(model)\n",
    "    outputs = LSTM(units=88, activation='sigmoid', return_sequences=True)(model)\n",
    "#     model = Bidirectional(LSTM(units=128,\n",
    "#                                  activation='tanh',\n",
    "#                                  return_sequences=True), name='biLSTM'\n",
    "#                            )(model)\n",
    "#     outputs = Conv1D(filters=88, kernel_size=1, activation='sigmoid', padding='valid', name='conv5_output')(model)  \n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "def train_model(train_x,\n",
    "                validation_x,\n",
    "                input_heigth,\n",
    "                input_width,\n",
    "                epoch_num=30,\n",
    "                valid_steps=10,\n",
    "                epoch_steps=140,\n",
    "                use_tensorboard=False,\n",
    "                model_type='conv'):\n",
    "    \"\"\"\n",
    "    Train specific model with given train and validation dataset.\n",
    "    \n",
    "    Args:\n",
    "        train_x: tf.data.Dataset object which yields train inputs as generator\n",
    "        validation_x: tf.data.Dataset object which yields validation inputs as generator\n",
    "        input_height/input_width: input parameters defining model shape\n",
    "        epoch_num: number of epochs\n",
    "        valid_steps: number of validation steps after each epoch\n",
    "        epoch_steps: steps per epoch\n",
    "        use_tensorboard: if model should use TensorBoard\n",
    "        model_type: type of model to train (conv or lstm)\n",
    "    \n",
    "    Return:\n",
    "        model: trained model, which is ready to be evaluated\n",
    "        history: callback containing model history (loss and accuracy)\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    adam_opt = Adam(lr=0.006, decay=1e-5)\n",
    "    \n",
    "    if model_type == 'conv':\n",
    "        model = create_conv_model(input_heigth, input_width)\n",
    "    elif model_type == 'lstm':\n",
    "        model = create_acoustic_model(input_heigth, input_width)\n",
    "    else:\n",
    "        raise ValueError('Wrong model type. Expecting values \"conv\" or \"lstm\"')\n",
    "   \n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "#     checkpoint = ModelCheckpoint('weights.best.hdf5',\n",
    "#                                  monitor='val_acc',\n",
    "#                                  verbose=1,\n",
    "#                                  save_best_only=True,\n",
    "#                                  mode='max')\n",
    "    \n",
    "    if use_tensorboard is True:\n",
    "        \n",
    "        tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),\n",
    "                                  write_grads=True,\n",
    "                                  histogram_freq=1,\n",
    "                                  write_images=True)\n",
    "        \n",
    "        history = model.fit(train_x.make_one_shot_iterator(),\n",
    "                  validation_data=validation_x.make_one_shot_iterator(),\n",
    "                  validation_steps=valid_steps,\n",
    "                  epochs=epoch_num,\n",
    "                  steps_per_epoch=epoch_steps,\n",
    "                  verbose=1,\n",
    "                  callbacks=[tensorboard]\n",
    "             )\n",
    "    else:\n",
    "        history = model.fit(train_x.make_one_shot_iterator(),\n",
    "                      validation_data=validation_x.make_one_shot_iterator(),\n",
    "                      validation_steps=valid_steps,\n",
    "                      epochs=epoch_num,\n",
    "                      steps_per_epoch=epoch_steps,\n",
    "                      verbose=1\n",
    "                 )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    Util for plotting model training history.\n",
    "    \n",
    "    Args:\n",
    "        history: tf.keras.callbacks.History object\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.tick_params(labelsize=17)\n",
    "    plt.ylabel('accuracy', fontsize=19)\n",
    "    plt.xlabel('epoch', fontsize=19)\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    # plt.savefig('acc_history_conv.png', format='png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.tick_params(labelsize=17)\n",
    "    plt.ylabel('loss', fontsize=19)\n",
    "    plt.xlabel('epoch', fontsize=19)\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    # plt.savefig('loss_history_conv.png', format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Metrics calculation for model predictions\"\"\"\n",
    "\n",
    "def get_test_data(dataset):\n",
    "    \"\"\"Generate whole test dataset for model evaluation\"\"\"\n",
    "    \n",
    "    it = dataset.make_initializable_iterator()\n",
    "    el = it.get_next()\n",
    "    \n",
    "    test_data = []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(it.initializer)\n",
    "        \n",
    "        for _ in range(50):\n",
    "            batch = sess.run(el)\n",
    "            test_data.append(batch)\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "def get_loss_acc(dataset, model):\n",
    "    \"\"\"Get loss and accurancy from model\"\"\"\n",
    "    \n",
    "    metrics = []\n",
    "    for cqt, midi in dataset:\n",
    "        metrics.append(model.test_on_batch(cqt, midi))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def get_metrics(dataset, model, threshold=0.4):\n",
    "    \"\"\"\n",
    "    Generate metrics - precision, recall, F1 - for model usign test dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset: generated dataset with tuples in format (cqt, midi)\n",
    "        model: trained model for predicting\n",
    "        threshold: predictions thresholds\n",
    "    \n",
    "    Return:\n",
    "        precision, recall and F1 score metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    thresh_predictions = []\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for tup in dataset:\n",
    "        prediction = model.predict(tup)\n",
    "        prediction = np.concatenate(prediction, axis=0)\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # apply threshold\n",
    "        thresh_prediction = np.array([[1 if row > threshold else 0 for row in col] for col in prediction])\n",
    "        thresh_predictions.append(thresh_prediction)\n",
    "        \n",
    "        label = np.concatenate(tup[1], axis=0)\n",
    "        label = np.array([[1 if row > 0.5 else 0 for row in col] for col in label])\n",
    "        labels.append(label)\n",
    "        \n",
    "    precision_metrics = []\n",
    "    recall_metrics = []\n",
    "    F1_metrics = []\n",
    "    for predict, thresh, lbl in zip(predictions, thresh_predictions, labels):\n",
    "        tmp_lbl = np.ndarray.flatten(lbl)\n",
    "        tmp_thresh = np.ndarray.flatten(thresh)\n",
    "        tmp_predict = np.ndarray.flatten(predict)\n",
    "        precision, recall, thresholds = precision_recall_curve(tmp_lbl, tmp_predict)\n",
    "        precision = sklearn.metrics.precision_score(tmp_lbl, tmp_thresh)\n",
    "        recall = sklearn.metrics.recall_score(tmp_lbl, tmp_thresh)\n",
    "        F1 = f1_score(tmp_lbl, tmp_thresh)\n",
    "        precision_metrics.append(precision)\n",
    "        recall_metrics.append(recall)\n",
    "        F1_metrics.append(F1)\n",
    "    \n",
    "    return precision_metrics, recall_metrics, F1_metrics\n",
    "\n",
    "def show_metrics(test_dataset, model):\n",
    "    \"\"\"Generate and print metrics\"\"\"\n",
    "    \n",
    "    t_dataset = get_test_data(test_dataset)\n",
    "    precision_metrics, recall_metrics, F1_score = get_metrics(t_dataset, model)\n",
    "    print(np.mean(precision_metrics), np.mean(recall_metrics), np.mean(F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSaved models,\\nonly load if needed.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Saved models,\n",
    "only load if needed.\n",
    "\"\"\"\n",
    "# model = tf.keras.models.load_model('frames_conv_model1.h5')\n",
    "# model = tf.keras.models.load_model('onsets_conv_model1.h5')\n",
    "# model = tf.keras.models.load_model('onsets_lstm_model1.h5')\n",
    "# model = tf.keras.models.load_model('frames_lstm_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_dataset, valid_dataset, test_dataset = prep.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height, width = c.SEQUENCE_CHUNK_LENGTH + 2*c.CHUNK_PADDING, c.BINS_NUMBER\n",
    "# model, history = train_model(train_dataset, valid_dataset, height, width, use_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model = tf.keras.models.load_model('weights.best.no3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_history = saved_model.fit(train_dataset.make_one_shot_iterator(),\n",
    "#                   validation_data=valid_dataset.make_one_shot_iterator(),\n",
    "#                   validation_steps=10,\n",
    "#                   epochs=34,\n",
    "#                   steps_per_epoch=140,\n",
    "#                   verbose=1, initial_epoch=24,\n",
    "#                   callbacks=[tensorboard, checkpoint]\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset, valid_dataset, test_dataset = prep.get_dataset_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show_metrics(test_dataset, saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# it = test_dataset.make_initializable_iterator()\n",
    "# cqt_batch = []\n",
    "# midi_batch = []\n",
    "# el = it.get_next()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(it.initializer)\n",
    "\n",
    "#     batch = sess.run(el)\n",
    "\n",
    "# saved_model.test_on_batch(batch[0],batch[1])\n",
    "# model.evaluate_generator(generator=test_dataset.make_one_shot_iterator(), steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onset_predict = saved_model.predict(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate_generator(test_dataset.make_initializable_iterator(), steps=20)\n",
    "# train_pairs, valid_pairs, test_pairs = prep.get_datasets_pairs()\n",
    "# test_dataset_generator = test_data_generator(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([[1 if row>0.4 else 0 for row in col] for col in np.concatenate(onset_predict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep.mp.plot_piano_roll(x.T)\n",
    "# plt.xlabel('Time', fontsize=17)\n",
    "# plt.ylabel('Note', fontsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prep.mp.plot_piano_roll(np.concatenate(batch[1]).T)\n",
    "# plt.xlabel('Time', fontsize=17)\n",
    "# plt.ylabel('Note', fontsize=17)\n",
    "# plt.tick_params(labelsize=12)\n",
    "# plt.savefig(\"BP.png\", format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([[1 if row>0.5 else 0 for row in col] for col in x])\n",
    "# prep.mp.plot_piano_roll(x.T)\n",
    "# plt.xlabel('Time', fontsize=17)\n",
    "# plt.ylabel('Note', fontsize=17)\n",
    "# plt.tick_params(labelsize=12)\n",
    "# plt.savefig(\"BP.png\", format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws2 = np.array(prep.wav_chunks[0])\n",
    "# wavs_reshaped2 = np.array([w.T for w in ws2])\n",
    "# wsr2 = np.array([w.reshape(4, 264, 1) for w in wavs_reshaped2])\n",
    "# msr2 = prep.midi_chunks[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep.mp.plot_piano_roll(midi_predicted[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_m = prep.pretty_midi.PrettyMIDI('D:\\School\\Bc\\model\\MAPS\\AkPnBcht\\MUS\\MAPS_MUS-scn16_2_AkPnBcht.mid')\n",
    "# midi_m = midi_m.get_piano_roll(fs=c.FRAME_LENGTH)[c.MIDI_MIN:c.MIDI_MAX+1, :]\n",
    "# prep.mp.plot_piano_roll(midi_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cqt_m = prep.ap.cqt_matrix('D:\\School\\Bc\\model\\MAPS\\AkPnBsdf\\MUS\\MAPS_MUS-alb_se3_AkPnBsdf.wav')\n",
    "# cqt_m = prep.ap.cqt_matrix('\\data\\shared\\MAPS\\AkPnBcht\\MUS\\MAPS_MUS-chpn-p8_AkPnBcht.wav')\n",
    "# cqt_m = prep.log_normalization(cqt_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
