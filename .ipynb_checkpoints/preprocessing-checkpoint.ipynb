{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of audio and MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from audio_prep.ipynb\n",
      "importing Jupyter notebook from constants.ipynb\n",
      "importing Jupyter notebook from midi_prep.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import audio_prep as ap, midi_prep as mp, constants as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi_wav_pairs(path):\n",
    "    \"\"\"Create pairs of wav and midi files from specified path\"\"\"\n",
    "    \n",
    "    files = listdir(path)\n",
    "    wavs = [wav[:-4] for wav in files if wav.endswith('.wav')]\n",
    "    midis = [midi[:-4] for midi in files if midi.endswith('.mid')]\n",
    "    \n",
    "    pairs = []\n",
    "    for file in wavs:\n",
    "        if file not in midis:\n",
    "            # Inform about file without pair and continue\n",
    "            print('No matching pair for file: ', file)\n",
    "        else:\n",
    "            pairs.append((file + '.wav', file + '.mid'))\n",
    "    return pairs\n",
    "\n",
    "def load_midi_wav_pairs(path, pairs):\n",
    "    \"\"\"Load pairs as WAV and MIDI matrices\"\"\"\n",
    "    \n",
    "    cqt_matrices = []\n",
    "    midi_matrices = []\n",
    "    raw_MIDIs = []\n",
    "    \n",
    "    print(\"Loading \", len(pairs), \"files.\")\n",
    "    for i, file in enumerate(pairs):\n",
    "        # Load WAV file\n",
    "        cqt_matrix = ap.cqt_matrix(path + '\\\\' + file[0])\n",
    "        cqt_matrices.append(np.array(cqt_matrix))\n",
    "        \n",
    "        # Load MIDI file\n",
    "        midi = pretty_midi.PrettyMIDI(path + '\\\\' + file[1])\n",
    "        midi_matrix = midi.get_piano_roll(fs=c.FRAMES_PER_SEC)[c.MIDI_MIN:c.MIDI_MAX+1, :]\n",
    "        midi_matrices.append(np.array(midi_matrix))\n",
    "        raw_MIDIs.append(midi)\n",
    "        \n",
    "        if i % 3 == 0:\n",
    "            print(\"Successfully loaded \", i+1 , \" file(s)\")\n",
    "    \n",
    "    print(\"Loading successfull!\")\n",
    "    return cqt_matrices, midi_matrices, raw_MIDIs\n",
    "\n",
    "def align_midi_wav_pairs(cqt_matrices,\n",
    "                         midi_matrices,\n",
    "                         matrices_type=\"single_pair\"):\n",
    "    \"\"\"Align the time shapes of CQT and MIDI metrices\"\"\"\n",
    "    \n",
    "    if matrices_type == \"single_pair\":\n",
    "        print(\"Aligning single pair of CQT spectrogram and MIDI matrix\")\n",
    "        cqt_length = len(cqt_matrices[0])\n",
    "        midi_length = len(midi_matrices[0])\n",
    "        \n",
    "        if cqt_length > midi_length:\n",
    "            print(\"Both matrices aligned to\", midi_length, \"frames.\")\n",
    "            return np.array(cqt_matrices[:, :midi_length]), np.array(midi_matrices)\n",
    "        elif cqt_length < midi_length:\n",
    "            print(\"Both matrices aligned to \", cqt_length, \"frames.\")\n",
    "            return np.array(cqt_matrices), np.array(midi_matrices[:, :cqt_length])\n",
    "        else:\n",
    "            print(\"Same length of matrices on input.\")\n",
    "            return np.array(cqt_matrices), np.array(midi_matrices)\n",
    "    elif matrices_type == \"array\":\n",
    "        aligned_cqts = []\n",
    "        aligned_midis = []\n",
    "        for cqt, midi in zip(cqt_matrices, midi_matrices):\n",
    "            cqt_shape = cqt[0].size\n",
    "            midi_shape = midi[0].size\n",
    "\n",
    "            if cqt_shape > midi_shape:\n",
    "                aligned_cqts.append(np.array(cqt[:, :midi_shape]))\n",
    "                aligned_midis.append(np.array(midi))\n",
    "            elif cqt_shape < midi_shape:\n",
    "                aligned_cqts.append(np.array(cqt))\n",
    "                aligned_midis.append(np.array(midi[:, :cqt_shape]))\n",
    "            else:\n",
    "                aligned_cqts.append(np.array(cqt))\n",
    "                aligned_midis.append(np.array(midi))\n",
    "                \n",
    "        return aligned_cqts, aligned_midis\n",
    "    else:\n",
    "        raise ValueError(\"Wrong matrices_type option. Only 'array' and 'single_pair' types allowed.\")\n",
    "\n",
    "def crop_midi_cqt_pairs(cqt_matrices,\n",
    "                        midi_matrices,\n",
    "                        operation_type=\"sequence\",\n",
    "                        matrices_type='single_pair'):\n",
    "\n",
    "    if matrices_type == 'single_pair':\n",
    "        return ap.cqt_split_to_sequence(cqt_matrices), mp.midi_split_to_sequence(midi_matrices)\n",
    "    \n",
    "    crop_cqt = []\n",
    "    crop_midis = []\n",
    "    if operation_type == \"sequence\":\n",
    "        for cqt, midi in zip(cqt_matrices, midi_matrices):\n",
    "            crop_cqt.append(ap.cqt_split_to_sequence(cqt))\n",
    "            crop_midis.append(mp.midi_split_to_sequence(midi))\n",
    "    elif operation_type == \"simple\":\n",
    "        for cqt, midi in zip(cqt_matrices, midi_matrices):\n",
    "            crop_cqt.append(np.array(ap.split_wav(cqt)))\n",
    "            crop_midis.append(np.array(mp.split_midi(midi)))\n",
    "    else:\n",
    "        raise ValueError(\"Wrong operation type.\")\n",
    "        \n",
    "    return crop_cqt, crop_midis\n",
    "\n",
    "def print_shapes(cqt_matrices, midi_matrices):\n",
    "    \"\"\"Print shapes of WAV and MIDI metrices\"\"\"\n",
    "    \n",
    "    for cqt, midi in zip(cqt_matrices, midi_matrices):\n",
    "        print(cqt.shape, midi.shape)\n",
    "        \n",
    "def log_normalization(cqt_matrix):\n",
    "    \"\"\"Perform basic logarithmic transformation with zero values shift constant\"\"\"\n",
    "    c = 10e-7\n",
    "    norm = [np.log(x+c) for x in cqt_matrix]\n",
    "    \n",
    "    # Shift to interval (-1,1)\n",
    "    n = np.min(norm)\n",
    "    d = np.max(norm) - n    \n",
    "    norm = [2*((x-n)/d)-1 for x in norm]\n",
    "    \n",
    "    return np.asarray(norm)\n",
    "\n",
    "def std_mean_normalization(cqt_matrix):\n",
    "    \"\"\"Normalization based on paper: An End-to-End Neural Network for Polyphonic Piano Music Transcription\"\"\"\n",
    "    std = np.std(cqt_matrix, axis=0)\n",
    "    mean = np.mean(cqt_matrix, axis=0)\n",
    "    norm = [(x-mean)/std for x in cqt_matrix]\n",
    "    \n",
    "    # Shift to interval (-1,1)\n",
    "    n = np.min(norm)\n",
    "    d = np.max(norm) - n    \n",
    "    norm = [2*((x-n)/d)-1 for x in norm]\n",
    "    return np.asarray(norm)\n",
    "\n",
    "def get_datasets_pairs():\n",
    "    \"\"\"Load pairs of paths and preprocess them\"\"\"\n",
    "    \n",
    "    train_path = r'non-overlapping/train'\n",
    "    valid_path = r'non-overlapping/valid'\n",
    "    test_path = r'non-overlapping/test'\n",
    "    \n",
    "    train_pairs = []\n",
    "    valid_pairs = []\n",
    "    test_pairs = []\n",
    "    \n",
    "    train_file = open(train_path, \"r\")\n",
    "    valid_file = open(valid_path, \"r\")\n",
    "    test_file = open(test_path, \"r\")\n",
    "    for line in train_file:\n",
    "        pairs = line.split(sep=',')\n",
    "        train_pairs.append((pairs[0], pairs[1][:-1]))\n",
    "    train_file.close()\n",
    "    \n",
    "    for line in valid_file:\n",
    "        pairs = line.split(sep=',')\n",
    "        valid_pairs.append((pairs[0], pairs[1][:-1]))\n",
    "    valid_file.close()\n",
    "    \n",
    "    for line in test_file:\n",
    "        pairs = line.split(sep=',')\n",
    "        test_pairs.append((pairs[0], pairs[1][:-1]))\n",
    "    test_file.close()\n",
    "    \n",
    "    return train_pairs, valid_pairs, test_pairs\n",
    "    \n",
    "\n",
    "def process_data(file_pairs):\n",
    "    for pair in file_pairs:\n",
    "        cqt_spectrogram = ap.cqt_matrix(pair[0])\n",
    "        piano_roll = mp.load_midi_file(pair[1])        \n",
    "        frame_one_hot = mp.pretty_midi_to_frame_matrix(piano_roll)       \n",
    "        cqt_spectrogram, frame_one_hot = align_midi_wav_pairs(cqt_spectrogram,\n",
    "                                                              frame_one_hot,\n",
    "                                                              matrices_type=\"single_pair\")\n",
    "        normalized_cqt_spec = log_normalization(cqt_spectrogram)        \n",
    "        cqt_spectrogram, frame_one_hot = crop_midi_cqt_pairs(normalized_cqt_spec, frame_one_hot)\n",
    "        cqt_spectrogram = cqt_spectrogram[:-1]\n",
    "        frame_one_hot = frame_one_hot[:-1]\n",
    "        for cqt, one_hot in zip(cqt_spectrogram, frame_one_hot):\n",
    "            cqt = cqt.reshape((c.BINS_NUMBER, c.SEQUENCE_CHUNK_LENGTH + 2*c.CHUNK_PADDING, 1))\n",
    "            yield cqt, one_hot\n",
    "\n",
    "def get_dataset():\n",
    "    train_pairs, valid_pairs, test_pairs = get_datasets_pairs()\n",
    "    \n",
    "#     path = r'D:\\School\\Bc\\model\\MAPS\\AkPnBcht\\MUS'\n",
    "#     pairs = create_midi_wav_pairs(path)\n",
    "    generator = lambda: process_data(train_pairs)\n",
    "    return tf.data.Dataset.from_generator(generator, (tf.float32, tf.float32)).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_pairs, valid_pairs, test_pairs = get_datasets_pairs()\n",
    "# for pair in train_pairs:\n",
    "#     print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'D:\\School\\Bc\\model\\MAPS\\AkPnBcht\\MUS'\n",
    "# pairs = create_midi_wav_pairs(path)\n",
    "# pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cqt_matrices, midis, raw_midis = load_midi_wav_pairs(path, pairs)\n",
    "# onset_midi = [mp.pretty_midi_to_onset_matrix(midi) for midi in raw_midis]\n",
    "# frame_midi = [mp.pretty_midi_to_frame_matrix(midi) for midi in midis]\n",
    "# cqt_matrices, frame_midi = align_midi_wav_pairs(cqt_matrices, frame_midi, matrices_type='array')\n",
    "# cqt_norm = [log_normalization(wav) for wav in cqt_matrices]\n",
    "# cqt_chunks, midi_chunks = crop_midi_cqt_pairs(cqt_norm, frame_midi, matrices_type='array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\silvopc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "dataset1 = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\silvopc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Aligning single pair of CQT spectrogram and MIDI matrix\n",
      "Both matrices aligned to 7752 frames.\n",
      "(8, 264, 629, 1) (8, 88, 625)\n"
     ]
    }
   ],
   "source": [
    "it = dataset1.make_initializable_iterator()\n",
    "\n",
    "el = it.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(it.initializer)\n",
    "    output_sess1, output_sess2 = sess.run(el)\n",
    "    print(output_sess1.shape, output_sess2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
