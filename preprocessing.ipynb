{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of audio and MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2f2a731be3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio_prep\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi_prep\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import audio_prep as ap, midi_prep as mp, constants as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi_wav_pairs(path):\n",
    "    \"\"\"Create pairs of wav and midi files from specified path\"\"\"\n",
    "    \n",
    "    files = listdir(path)\n",
    "    wavs = [wav[:-4] for wav in files if wav.endswith('.wav')]\n",
    "    midis = [midi[:-4] for midi in files if midi.endswith('.mid')]\n",
    "    \n",
    "    pairs = []\n",
    "    for file in wavs:\n",
    "        if file not in midis:\n",
    "            # Inform about file without pair and continue\n",
    "            print('No matching pair for file: ', file)\n",
    "        else:\n",
    "            pairs.append((file + '.wav', file + '.mid'))\n",
    "    return pairs\n",
    "\n",
    "def load_midi_wav_pairs(path, pairs):\n",
    "    \"\"\"Load pairs as CQT and piano roll matrices\"\"\"\n",
    "    \n",
    "    cqt_matrices = []\n",
    "    midi_matrices = []\n",
    "    raw_MIDIs = []\n",
    "    \n",
    "    print(\"Loading \", len(pairs), \"files.\")\n",
    "    for i, file in enumerate(pairs):\n",
    "        # Load WAV file\n",
    "        cqt_matrix = ap.cqt_matrix(path + '\\\\' + file[0])\n",
    "        cqt_matrices.append(np.array(cqt_matrix))\n",
    "        \n",
    "        # Load MIDI file\n",
    "        midi = pretty_midi.PrettyMIDI(path + '\\\\' + file[1])\n",
    "        midi_matrix = midi.get_piano_roll(fs=c.FRAMES_PER_SEC)[c.MIDI_MIN:c.MIDI_MAX+1, :]\n",
    "        midi_matrices.append(np.array(midi_matrix))\n",
    "        raw_MIDIs.append(midi)\n",
    "        \n",
    "        if i % 3 == 0:\n",
    "            print(\"Successfully loaded \", i+1 , \" file(s)\")\n",
    "    \n",
    "    print(\"Loading successfull!\")\n",
    "    return cqt_matrices, midi_matrices, raw_MIDIs\n",
    "\n",
    "def align_midi_wav_pairs(cqt_matrices,\n",
    "                         midi_matrices,\n",
    "                         matrices_type=\"single_pair\"):\n",
    "    \"\"\"\n",
    "    Align the time shapes of CQT and MIDI metrices\n",
    "    \n",
    "    Args:\n",
    "        cqt_matrices: CQT matrix/matrices to align\n",
    "        midi_matrices: piano roll matrix/matrices to align\n",
    "        matrices_type: 'single_pair' for only one sequence alignment\n",
    "                       'array' for multiple sequences alignment\n",
    "    \n",
    "    Returns:\n",
    "        aligned_cqts, aligned_midis: aligned pairs of sequences\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: if you provide wrong matrices_type parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    if matrices_type == \"single_pair\":\n",
    "        print(\"Aligning single pair of CQT spectrogram and MIDI matrix\")\n",
    "        cqt_length = len(cqt_matrices[0])\n",
    "        midi_length = len(midi_matrices[0])\n",
    "        \n",
    "        if cqt_length > midi_length:\n",
    "            print(\"Both matrices aligned to\", midi_length, \"frames.\")\n",
    "            return np.array(cqt_matrices[:, :midi_length]), np.array(midi_matrices)\n",
    "        elif cqt_length < midi_length:\n",
    "            print(\"Both matrices aligned to \", cqt_length, \"frames.\")\n",
    "            return np.array(cqt_matrices), np.array(midi_matrices[:, :cqt_length])\n",
    "        else:\n",
    "            print(\"Same length of matrices on input.\")\n",
    "            return np.array(cqt_matrices), np.array(midi_matrices)\n",
    "    elif matrices_type == \"array\":\n",
    "        aligned_cqts = []\n",
    "        aligned_midis = []\n",
    "        for cqt, midi in zip(cqt_matrices, midi_matrices):\n",
    "            cqt_shape = cqt[0].size\n",
    "            midi_shape = midi[0].size\n",
    "\n",
    "            if cqt_shape > midi_shape:\n",
    "                aligned_cqts.append(np.array(cqt[:, :midi_shape]))\n",
    "                aligned_midis.append(np.array(midi))\n",
    "            elif cqt_shape < midi_shape:\n",
    "                aligned_cqts.append(np.array(cqt))\n",
    "                aligned_midis.append(np.array(midi[:, :cqt_shape]))\n",
    "            else:\n",
    "                aligned_cqts.append(np.array(cqt))\n",
    "                aligned_midis.append(np.array(midi))\n",
    "                \n",
    "        return aligned_cqts, aligned_midis\n",
    "    else:\n",
    "        raise ValueError(\"Wrong matrices_type option. Only 'array' and 'single_pair' types allowed.\")\n",
    "\n",
    "def crop_midi_cqt_pairs(cqt_matrices,\n",
    "                        midi_matrices,\n",
    "                        operation_type=\"sequence\",\n",
    "                        matrices_type='single_pair'):\n",
    "    \"\"\"\n",
    "    Crop CQT and piano roll pairs into sequences.\n",
    "    \n",
    "    Args:\n",
    "        cqt_matrices: CQT matrix/matrices to crop\n",
    "        midi_matrices: piano roll matrix/matrices to crop\n",
    "        operation_type: if the output is single frame sequence or\n",
    "                        sequence of specific length\n",
    "        matrices_type: 'single_pair' for only one sequence crop\n",
    "                       'array' for multiple sequences crop\n",
    "                       \n",
    "    Returns:\n",
    "        crop_cqt, crop_midis: lists of cropped sequences\n",
    "    \"\"\"\n",
    "\n",
    "    if matrices_type == 'single_pair':\n",
    "        return ap.cqt_split_to_sequence(cqt_matrices), mp.midi_split_to_sequence(midi_matrices)\n",
    "    \n",
    "    crop_cqt = []\n",
    "    crop_midis = []\n",
    "    if operation_type == \"sequence\":\n",
    "        for cqt, midi in zip(cqt_matrices, midi_matrices):\n",
    "            crop_cqt.append(ap.cqt_split_to_sequence(cqt))\n",
    "            crop_midis.append(mp.midi_split_to_sequence(midi))\n",
    "    elif operation_type == \"simple\":\n",
    "        for cqt, midi in zip(cqt_matrices, midi_matrices):\n",
    "            crop_cqt.append(np.array(ap.split_wav(cqt)))\n",
    "            crop_midis.append(np.array(mp.split_midi(midi)))\n",
    "    else:\n",
    "        raise ValueError(\"Wrong operation type.\")\n",
    "        \n",
    "    return crop_cqt, crop_midis\n",
    "\n",
    "def print_shapes(cqt_matrices, midi_matrices):\n",
    "    \"\"\"Print shapes of WAV and MIDI metrices\"\"\"\n",
    "    \n",
    "    for cqt, midi in zip(cqt_matrices, midi_matrices):\n",
    "        print(cqt.shape, midi.shape)\n",
    "        \n",
    "def log_normalization(cqt_matrix):\n",
    "    \"\"\"Perform basic logarithmic transformation with zero values shift constant\"\"\"\n",
    "    c = 10e-7\n",
    "    norm = [np.log(x+c) for x in cqt_matrix]\n",
    "    \n",
    "    # Shift to interval (-1,1)\n",
    "    n = np.min(norm)\n",
    "    d = np.max(norm) - n    \n",
    "    norm = [2*((x-n)/d)-1 for x in norm]\n",
    "    \n",
    "    return np.asarray(norm)\n",
    "\n",
    "def std_mean_normalization(cqt_matrix):\n",
    "    \"\"\"Normalization based on paper: An End-to-End Neural Network for Polyphonic Piano Music Transcription\"\"\"\n",
    "    \n",
    "    std = np.std(cqt_matrix, axis=0)\n",
    "    mean = np.mean(cqt_matrix, axis=0)\n",
    "    norm = [(x-mean)/std for x in cqt_matrix]\n",
    "    \n",
    "    # Shift to interval (-1,1)\n",
    "    n = np.min(norm)\n",
    "    d = np.max(norm) - n    \n",
    "    norm = [2*((x-n)/d)-1 for x in norm]\n",
    "    return np.asarray(norm)\n",
    "\n",
    "def get_datasets_pairs():\n",
    "    \"\"\"Load pairs from paths and preprocess them\"\"\"\n",
    "    \n",
    "    train_path = r'non-overlapping/train'\n",
    "    valid_path = r'non-overlapping/valid'\n",
    "    test_path = r'non-overlapping/test'\n",
    "    \n",
    "    train_pairs = []\n",
    "    valid_pairs = []\n",
    "    test_pairs = []\n",
    "    \n",
    "    train_file = open(train_path, \"r\")\n",
    "    valid_file = open(valid_path, \"r\")\n",
    "    test_file = open(test_path, \"r\")\n",
    "    for line in train_file:\n",
    "        pairs = line.split(sep=',')\n",
    "        train_pairs.append((pairs[0], pairs[1][:-1]))\n",
    "    train_file.close()\n",
    "    \n",
    "    for line in valid_file:\n",
    "        pairs = line.split(sep=',')\n",
    "        valid_pairs.append((pairs[0], pairs[1][:-1]))\n",
    "    valid_file.close()\n",
    "    \n",
    "    for line in test_file:\n",
    "        pairs = line.split(sep=',')\n",
    "        test_pairs.append((pairs[0], pairs[1][:-1]))\n",
    "    test_file.close()\n",
    "    \n",
    "    return train_pairs, valid_pairs, test_pairs\n",
    "\n",
    "\n",
    "def process_data(file_pairs, predictions='frame'):\n",
    "    \"\"\"\n",
    "    Generator function for datasets processing.\n",
    "    \n",
    "    Args:\n",
    "        file_pairs: list of paths pairs to dataset\n",
    "        predictions: 'frame' to set labels to frames one-hot matrix\n",
    "                     'onset' to set labels to onsets one-hot matrix\n",
    "    \n",
    "    Yields:\n",
    "        cqt, one-hot: CQT sequence with corresponding one-hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    counter = 0;\n",
    "    for pair in file_pairs:\n",
    "        cqt_spectrogram = ap.cqt_matrix(pair[0])\n",
    "        \n",
    "        if predictions == 'frame':\n",
    "            piano_roll = mp.load_midi_file(pair[1])        \n",
    "            one_hot = mp.pretty_midi_to_frame_matrix(piano_roll)\n",
    "        elif predictions == 'onset':\n",
    "            raw_midi = pretty_midi.PrettyMIDI(pair[1])\n",
    "            one_hot = mp.pretty_midi_to_onset_matrix(raw_midi)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong predictions operation type.\")\n",
    "        \n",
    "        cqt_spectrogram, one_hot = align_midi_wav_pairs(cqt_spectrogram,\n",
    "                                                        one_hot,\n",
    "                                                        matrices_type=\"single_pair\")\n",
    "        normalized_cqt_spec = log_normalization(cqt_spectrogram)        \n",
    "        cqt_spectrogram, one_hot = crop_midi_cqt_pairs(normalized_cqt_spec, one_hot)\n",
    "        cqt_spectrogram = cqt_spectrogram[:-1]\n",
    "        one_hot = one_hot[:-1]\n",
    "        counter += len(cqt_spectrogram)\n",
    "        print(\"Currently processed \", counter, \"sequences.\")\n",
    "        for cqt, one_hot in zip(cqt_spectrogram, one_hot):\n",
    "            cqt = cqt.T\n",
    "            one_hot = one_hot.T\n",
    "            cqt = cqt.reshape(*cqt.shape, -1)\n",
    "#             cqt = cqt.reshape((c.SEQUENCE_CHUNK_LENGTH + 2*c.CHUNK_PADDING, c.BINS_NUMBER, 1))\n",
    "            yield cqt, one_hot\n",
    "\n",
    "def get_dataset():\n",
    "    \"\"\"\n",
    "    Process datasets as tf.data.Dataset objects which are filled with generators.\n",
    "    \n",
    "    Returns:\n",
    "        train_dataset, valid_dataset, test_dataset: dataset generators\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    train_pairs, valid_pairs, test_pairs = get_datasets_pairs()\n",
    "    \n",
    "#     path = r'D:\\School\\Bc\\model\\MAPS\\AkPnBcht\\MUS'\n",
    "#     pairs = create_midi_wav_pairs(path)\n",
    "    train_generator = lambda: process_data(train_pairs, predictions='frame')\n",
    "    valid_generator = lambda: process_data(valid_pairs, predictions='frame')\n",
    "    test_generator = lambda: process_data(test_pairs, predictions='frame')\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_generator(train_generator,\n",
    "                                                   (tf.float32, tf.float32)).batch(c.BATCH_SIZE)\n",
    "    train_dataset = train_dataset.apply(tf.data.experimental.shuffle_and_repeat(128))\n",
    "    \n",
    "    valid_dataset = tf.data.Dataset.from_generator(valid_generator,\n",
    "                                                   (tf.float32, tf.float32)).batch(c.BATCH_SIZE)\n",
    "    valid_dataset = valid_dataset.apply(tf.data.experimental.shuffle_and_repeat(9))\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_generator(test_generator,\n",
    "                                                  (tf.float32, tf.float32)).batch(c.BATCH_SIZE)\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "def get_dataset_test():\n",
    "    \"\"\"Testing util (same as get_dataset() function) with smaller generators\"\"\"\n",
    "    \n",
    "    train_pairs, valid_pairs, test_pairs = get_datasets_pairs()\n",
    "    \n",
    "#     path = r'D:\\School\\Bc\\model\\MAPS\\AkPnBcht\\MUS'\n",
    "#     pairs = create_midi_wav_pairs(path)\n",
    "    train_generator = lambda: process_data(train_pairs, predictions='frame')\n",
    "    valid_generator = lambda: process_data(valid_pairs, predictions='frame')\n",
    "    test_generator = lambda: process_data(test_pairs, predictions='frame')\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_generator(train_generator,\n",
    "                                                   (tf.float32, tf.float32)).batch(c.BATCH_SIZE)\n",
    "    train_dataset = train_dataset.apply(tf.data.experimental.shuffle_and_repeat(3))\n",
    "    \n",
    "    valid_dataset = tf.data.Dataset.from_generator(valid_generator,\n",
    "                                                   (tf.float32, tf.float32)).batch(c.BATCH_SIZE)\n",
    "    valid_dataset = valid_dataset.apply(tf.data.experimental.shuffle_and_repeat(3))\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_generator(test_generator,\n",
    "                                                  (tf.float32, tf.float32)).batch(c.BATCH_SIZE)\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_d, valid_d, test_d = get_dataset()\n",
    "# for pair in train_pairs:\n",
    "#     print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'D:\\School\\Bc\\model\\MAPS\\AkPnBcht\\MUS'\n",
    "# pairs = create_midi_wav_pairs(path)\n",
    "# pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cqt_matrices, midis, raw_midis = load_midi_wav_pairs(path, pairs)\n",
    "# onset_midi = [mp.pretty_midi_to_onset_matrix(midi) for midi in raw_midis]\n",
    "# frame_midi = [mp.pretty_midi_to_frame_matrix(midi) for midi in midis]\n",
    "# cqt_matrices, frame_midi = align_midi_wav_pairs(cqt_matrices, frame_midi, matrices_type='array')\n",
    "# cqt_norm = [log_normalization(wav) for wav in cqt_matrices]\n",
    "# cqt_chunks, midi_chunks = crop_midi_cqt_pairs(cqt_norm, frame_midi, matrices_type='array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it1, it2, it3 = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# it = test_d.make_initializable_iterator()\n",
    "\n",
    "# el = it.get_next()\n",
    "# counter = 1\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(it.initializer)\n",
    "\n",
    "#     c, m = sess.run(el)\n",
    "#     print(c.shape,m.shape)\n",
    "#     ap.create_spectrogram(c[2:627,:,0].T)\n",
    "#     mp.plot_piano_roll(m.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
